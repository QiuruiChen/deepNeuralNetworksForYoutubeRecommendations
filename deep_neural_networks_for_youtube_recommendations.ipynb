{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural networks for youtube recommendations ( generator)\n",
    "\n",
    "- data source: watch history + user search history + other features \n",
    "- watch history:\n",
    "    - a vriable-length sequence of saprse video Ids ==> a dense vector (embeddings)\n",
    "    - fixed-sized dense inputs and averaging the embeddings (sum, or componnet-wise max, etc)\n",
    "    - embeddings are learned \n",
    "    - embedding: fixed vocabulary; \n",
    "\n",
    "- user search history: similar to watch history \n",
    "    - query : tokenized into unigrams and bigrams \n",
    "    - token is embeded \n",
    "    - average ==> the user's tokenized, embeded queries represent a summarized dense search history\n",
    "\n",
    "- other features: \n",
    "    - geographic region+ device\n",
    "    - other features: simple binary and continous features (s.t. the user's gender, logged-in state, age) ==> normalized into 0-1\n",
    "    - example age: \n",
    "        - now() - video update time\n",
    "        - fresh videos are more preferable \n",
    "        - feature enginerring: example age, example age^2, sqrt(example age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/device:CPU:0',)\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CollectiveCommunication.AUTO\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json \n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "print(tf.__version__)\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "os.environ['TF_CONFIG'] = json.dumps({\n",
    "    'cluster': {\n",
    "        'worker': [\"localhost:12345\", \"localhost:23456\"]\n",
    "    },\n",
    "    'task': {'type': 'worker', 'index': 0}\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "- the data set form [Retailrocket recommender system dataset](https://www.kaggle.com/retailrocket/ecommerce-dataset)\n",
    "- event: user behaviour (only concerning 'transaction') \n",
    "- item_prop: item properties, changed by time, all values are hased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prop = pd.read_csv('data/item_properties_part1.csv')\n",
    "item_prop2 = pd.read_csv('data/item_properties_part2.csv')\n",
    "event = pd.read_csv('data/events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user behaviors: Index(['timestamp', 'visitorid', 'event', 'itemid', 'transactionid'], dtype='object')\n",
      "       timestamp  visitorid event  itemid  transactionid\n",
      "0  1433221332117     257597  view  355908            NaN\n",
      "1  1433224214164     992329  view  248676            NaN\n",
      "2  1433221999827     111016  view  318965            NaN\n",
      "3  1433221955914     483717  view  253185            NaN\n",
      "4  1433221337106     951259  view  367447            NaN\n",
      "user behviors include: ['view' 'addtocart' 'transaction']\n"
     ]
    }
   ],
   "source": [
    "print(\"user behaviors:\", event.columns)\n",
    "print(event.head(5))\n",
    "print(\"user behviors include:\", event['event'].unique())\n",
    "\n",
    "# only keep transaction, delete 'view' 'addtocart'\n",
    "event = event[event['event']=='transaction'].drop(columns={'event','transactionid'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess item property "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preview item properties data:         timestamp  itemid    property                            value\n",
      "0  1435460400000  460429  categoryid                             1338\n",
      "1  1441508400000  206783         888          1116713 960601 n277.200\n",
      "2  1439089200000  395014         400  n552.000 639502 n720.000 424566\n",
      "3  1431226800000   59481         790                       n15360.000\n",
      "4  1431831600000  156781         917                           828513\n",
      "5  1436065200000  285026   available                                0\n",
      "6  1434250800000   89534         213                          1121373\n",
      "7  1431831600000  264312           6                           319724\n",
      "8  1433646000000  229370         202                          1330310\n",
      "9  1434250800000   98113         451                  1141052 n48.000\n",
      "how many properties for item? 1097\n"
     ]
    }
   ],
   "source": [
    "print(\"preview item properties data: \",item_prop.head(10))\n",
    "print(\"how many properties for item?\", len(item_prop['property'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove categoryid and available in properties\n",
    "item_prop = item_prop[(item_prop['property'] != 'categoryid')& (item_prop['property'] != 'available')]\n",
    "item_prop2 = item_prop2[(item_prop2['property'] != 'categoryid')& (item_prop2['property'] != 'available')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x678074198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properties are not uniformed distributed, some properties are common among all items, some properties are only specific to some items\n",
    "popular_prop = item_prop.groupby('property')\\\n",
    "                        .size()\\\n",
    "                        .reset_index(name='count')\\\n",
    "                        .sort_values(by='count',ascending=False)\n",
    "popular_prop[['count']].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most popular properties are:\n",
      "     property    count\n",
      "972      888  1629817\n",
      "864      790   970800\n",
      "654        6   343207\n",
      "308      283   323681\n",
      "848      776   311654\n"
     ]
    }
   ],
   "source": [
    "print(\"the most popular properties are:\\n\", popular_prop.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select the top 5 popular item properties \n",
    "# thred = popular_prop['count'].quantile(0.98)\n",
    "thred = popular_prop['count'].iloc[5] \n",
    "poperty_selected = popular_prop[popular_prop['count'] > thred]['property'].values.tolist()\n",
    "\n",
    "item_prop = item_prop[item_prop['property'].isin(poperty_selected)]\n",
    "item_prop2 = item_prop2[item_prop2['property'].isin(poperty_selected)]\n",
    "\n",
    "# only select items that are appeared in user event\n",
    "item_prop= item_prop[item_prop['itemid'].isin(event.itemid.values.tolist())]\n",
    "item_prop2= item_prop2[item_prop2['itemid'].isin(event.itemid.values.tolist())]\n",
    "\n",
    "items = pd.concat([item_prop,item_prop2])\n",
    "del item_prop,item_prop2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    False\n",
       "itemid       False\n",
       "property     False\n",
       "value        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null data\n",
    "items.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand property into columns \n",
    "items = items.pivot_table(index=['timestamp','itemid'], \n",
    "                    columns='property', \n",
    "                    values='value',\n",
    "                    aggfunc='first').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert all the columns into string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preview items: \n",
      " property      timestamp  itemid  \\\n",
      "0         1431226800000      15   \n",
      "1         1431226800000      19   \n",
      "2         1431226800000      25   \n",
      "3         1431226800000      42   \n",
      "4         1431226800000     147   \n",
      "\n",
      "property                                                283                6  \\\n",
      "0         433564 245772 789221 809278 245772 1213953 429...              NaN   \n",
      "1                984060 150169 1037891 743822 552121 119805   353870 1310600   \n",
      "2                                                       NaN          1272323   \n",
      "3                       1285402 1042990 362953 731607 73247  1285402 1042990   \n",
      "4         726714 n36.000 1128577 n12.000 322971 229273 3...              NaN   \n",
      "\n",
      "property      776          790                                           888  \n",
      "0         1132786       n0.000                                           NaN  \n",
      "1             NaN   n14160.000                                        119805  \n",
      "2             NaN   n46800.000                                418093 1231777  \n",
      "3          905905  n244680.000                                         73247  \n",
      "4         1290577  n352416.000  229273 388993 1246541 321954 1079844 1103209  \n",
      "item columns are:\n",
      " Index(['timestamp', 'itemid', '283', '6', '776', '790', '888'], dtype='object', name='property')\n"
     ]
    }
   ],
   "source": [
    "print(\"preview items: \\n\",items.head(5))\n",
    "print(\"item columns are:\\n\",items.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['790'] = items['790'].fillna('n0.000') # this is the number property (maybe price)\n",
    "items = items.fillna('') #fill other prorperty with text ''\n",
    "\n",
    "items['item_prop_text'] = items['283']+ items['6']+items['776']+items['888']\n",
    "items['item_prop_num'] = items['790']\n",
    "\n",
    "# remove n in item_prop_num \n",
    "items['item_prop_num']  = items['item_prop_num'].str\\\n",
    "                            .replace('n(-*\\d+)\\.\\d{3}','\\\\1', regex=True)\\\n",
    "                            .astype(int)\n",
    "\n",
    "# remove n+numbers, only remain text hashes \n",
    "items['item_prop_text'] = items['item_prop_text'].replace('n-*\\d+\\.\\d{3}', '', regex=True)\n",
    "\n",
    "items = items.drop(columns= {'283', '6', '776', '790', '888'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remap hashed text into 0-n (since hased number is too big for int type)\n",
    "text_list = items['item_prop_text']\\\n",
    "            .apply(lambda x: list(set([int(ele) for ele in x.split(' ') \n",
    "                                        if (ele !='') and ('n' not in ele)]))).values.tolist()\n",
    "\n",
    "text_list = list(set([item for sublist in text_list for item in sublist]))\n",
    "text_list = sorted(text_list, key=int)\n",
    "map_word = dict(zip(text_list,range(len(text_list))))\n",
    "\n",
    "items['item_prop_text'] = items['item_prop_text'].apply(lambda x: [map_word[int(ele)] for ele in x.split(' ') \n",
    "                                        if (ele !='') and ('n' not in ele)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing event data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the event data:\n",
      "          timestamp  visitorid  itemid\n",
      "130  1433222276276     599528  356475\n",
      "304  1433193500981     121688   15335\n",
      "418  1433193915008     552148   81345\n",
      "814  1433176736375     102019  150318\n",
      "843  1433174518180     189384  310791\n",
      "the items data:\n",
      " property      timestamp  itemid  \\\n",
      "0         1431226800000      15   \n",
      "1         1431226800000      19   \n",
      "2         1431226800000      25   \n",
      "3         1431226800000      42   \n",
      "4         1431226800000     147   \n",
      "\n",
      "property                                     item_prop_text  item_prop_num  \n",
      "0         [10441, 5955, 18899, 19372, 5955, 28994, 10324...              0  \n",
      "1          [23503, 3615, 24805, 17840, 13270, 33803, 42269]          14160  \n",
      "2                                            [42021, 29404]          46800  \n",
      "3                 [30686, 24931, 8766, 17542, 38003, 45961]         244680  \n",
      "4         [17424, 26928, 7822, 5498, 9397, 29760, 7795, ...         352416  \n"
     ]
    }
   ],
   "source": [
    "print(\"the event data:\\n\",event.head(5))\n",
    "print(\"the items data:\\n\",items.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged data columns are: Index(['timestamp_x', 'visitorid', 'itemid', 'timestamp_y', 'item_prop_text',\n",
      "       'item_prop_num'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# combine item and event\n",
    "temp = event.merge(items,on=['itemid'])\n",
    "\n",
    "print(\"merged data columns are:\",temp.columns)\n",
    "\n",
    "\n",
    "temp = temp.rename(columns={'timestamp_x':'event_time', 'timestamp_y':'items_time'})\n",
    "# the item property changed timestamp should before event timestamp (aka transaction time)\n",
    "temp = temp[temp['event_time'] >temp['items_time'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each buying item, select only the most recently mofified item property\n",
    "temp['timestamp_diff'] = temp['event_time'] - temp['items_time']\n",
    "recent_temp = temp.groupby(['itemid','event_time'])['timestamp_diff'].min().reset_index()\n",
    "\n",
    "#each buying item should only have one corresponding item property\n",
    "assert recent_temp[['itemid','event_time']].duplicated().any() == False \n",
    "\n",
    "#  timestamp_diff == example_age (in the paper, this is kept)\n",
    "pre_event = pd.merge(recent_temp,temp, on=['timestamp_diff','itemid','event_time'])\\\n",
    "            .drop(columns={'items_time','timestamp_diff'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>event_time</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>item_prop_text</th>\n",
       "      <th>item_prop_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1436478142936</td>\n",
       "      <td>1124964</td>\n",
       "      <td>[27049]</td>\n",
       "      <td>8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1439663329849</td>\n",
       "      <td>325833</td>\n",
       "      <td>[]</td>\n",
       "      <td>18600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1433743130655</td>\n",
       "      <td>456617</td>\n",
       "      <td>[10073, 29404]</td>\n",
       "      <td>37320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1438647361098</td>\n",
       "      <td>575295</td>\n",
       "      <td>[10073, 29404, 27596]</td>\n",
       "      <td>39000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>1439431902653</td>\n",
       "      <td>432404</td>\n",
       "      <td>[1753, 17418]</td>\n",
       "      <td>199080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>147</td>\n",
       "      <td>1441036654674</td>\n",
       "      <td>582525</td>\n",
       "      <td>[5498, 9397, 29760, 7795, 25807, 26362, 26928,...</td>\n",
       "      <td>375816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>147</td>\n",
       "      <td>1441037956153</td>\n",
       "      <td>582525</td>\n",
       "      <td>[5498, 9397, 29760, 7795, 25807, 26362, 26928,...</td>\n",
       "      <td>375816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>1441038151733</td>\n",
       "      <td>582525</td>\n",
       "      <td>[5498, 9397, 29760, 7795, 25807, 26362, 26928,...</td>\n",
       "      <td>375816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>147</td>\n",
       "      <td>1441119453098</td>\n",
       "      <td>582525</td>\n",
       "      <td>[5498, 9397, 29760, 7795, 25807, 26362, 26928,...</td>\n",
       "      <td>375816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>168</td>\n",
       "      <td>1442451767273</td>\n",
       "      <td>152963</td>\n",
       "      <td>[]</td>\n",
       "      <td>46284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid     event_time  visitorid  \\\n",
       "0      15  1436478142936    1124964   \n",
       "1      19  1439663329849     325833   \n",
       "2      25  1433743130655     456617   \n",
       "3      25  1438647361098     575295   \n",
       "4      42  1439431902653     432404   \n",
       "5     147  1441036654674     582525   \n",
       "6     147  1441037956153     582525   \n",
       "7     147  1441038151733     582525   \n",
       "8     147  1441119453098     582525   \n",
       "9     168  1442451767273     152963   \n",
       "\n",
       "                                      item_prop_text  item_prop_num  \n",
       "0                                            [27049]           8400  \n",
       "1                                                 []          18600  \n",
       "2                                     [10073, 29404]          37320  \n",
       "3                              [10073, 29404, 27596]          39000  \n",
       "4                                      [1753, 17418]         199080  \n",
       "5  [5498, 9397, 29760, 7795, 25807, 26362, 26928,...         375816  \n",
       "6  [5498, 9397, 29760, 7795, 25807, 26362, 26928,...         375816  \n",
       "7  [5498, 9397, 29760, 7795, 25807, 26362, 26928,...         375816  \n",
       "8  [5498, 9397, 29760, 7795, 25807, 26362, 26928,...         375816  \n",
       "9                                                 []          46284  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_event.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each event, calculate purchasing history (purchased items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of expanded event df:  (860785, 9)\n",
      "the shape of orginal event df: (20757, 5)\n",
      "the columns of expanded event df: Index(['itemid_x', 'event_time_x', 'visitorid', 'item_prop_text_x',\n",
      "       'item_prop_num_x', 'itemid_y', 'event_time_y', 'item_prop_text_y',\n",
      "       'item_prop_num_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pre_event2 = pre_event.copy()\n",
    "explod_event = pre_event.merge(pre_event2,on=['visitorid'])\n",
    "\n",
    "print(\"the shape of expanded event df: \",explod_event.shape)\n",
    "print(\"the shape of orginal event df:\", pre_event.shape)\n",
    "print(\"the columns of expanded event df:\", explod_event.columns)\n",
    "\n",
    "explod_event = explod_event.rename(columns={\n",
    "                                    'event_time_x':'timestamp_hist', \n",
    "                                    'itemid_x':'itemid_hist', \n",
    "                                    'item_prop_text_x':'item_prop_text_hist',\n",
    "                                    'item_prop_num_x':'item_prop_num_hist',\n",
    "                                    'event_time_y':'timestamp_now',\n",
    "                                    'itemid_y':'itemid_now',\n",
    "                                    'item_prop_text_y':'item_prop_text_now',\n",
    "                                    'item_prop_num_y':'item_prop_num_now'\n",
    "                                    })\n",
    "\n",
    "# purchasing history timestamp should smaller than this purchasing timestamp\n",
    "explod_event = explod_event[explod_event['timestamp_hist']<explod_event['timestamp_now']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid_hist</th>\n",
       "      <th>timestamp_hist</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>item_prop_text_hist</th>\n",
       "      <th>item_prop_num_hist</th>\n",
       "      <th>itemid_now</th>\n",
       "      <th>timestamp_now</th>\n",
       "      <th>item_prop_text_now</th>\n",
       "      <th>item_prop_num_now</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1436478142936</td>\n",
       "      <td>1124964</td>\n",
       "      <td>[27049]</td>\n",
       "      <td>8400</td>\n",
       "      <td>66643</td>\n",
       "      <td>1436478142968</td>\n",
       "      <td>[]</td>\n",
       "      <td>53040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1436478142936</td>\n",
       "      <td>1124964</td>\n",
       "      <td>[27049]</td>\n",
       "      <td>8400</td>\n",
       "      <td>310720</td>\n",
       "      <td>1436478142968</td>\n",
       "      <td>[]</td>\n",
       "      <td>18720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1436478142936</td>\n",
       "      <td>1124964</td>\n",
       "      <td>[27049]</td>\n",
       "      <td>8400</td>\n",
       "      <td>348245</td>\n",
       "      <td>1436478142983</td>\n",
       "      <td>[]</td>\n",
       "      <td>8520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>16052</td>\n",
       "      <td>1436478142874</td>\n",
       "      <td>1124964</td>\n",
       "      <td>[]</td>\n",
       "      <td>50880</td>\n",
       "      <td>15</td>\n",
       "      <td>1436478142936</td>\n",
       "      <td>[27049]</td>\n",
       "      <td>8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>16052</td>\n",
       "      <td>1436478142874</td>\n",
       "      <td>1124964</td>\n",
       "      <td>[]</td>\n",
       "      <td>50880</td>\n",
       "      <td>66643</td>\n",
       "      <td>1436478142968</td>\n",
       "      <td>[]</td>\n",
       "      <td>53040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    itemid_hist  timestamp_hist  visitorid item_prop_text_hist  \\\n",
       "2            15   1436478142936    1124964             [27049]   \n",
       "7            15   1436478142936    1124964             [27049]   \n",
       "8            15   1436478142936    1124964             [27049]   \n",
       "10        16052   1436478142874    1124964                  []   \n",
       "12        16052   1436478142874    1124964                  []   \n",
       "\n",
       "    item_prop_num_hist  itemid_now  timestamp_now item_prop_text_now  \\\n",
       "2                 8400       66643  1436478142968                 []   \n",
       "7                 8400      310720  1436478142968                 []   \n",
       "8                 8400      348245  1436478142983                 []   \n",
       "10               50880          15  1436478142936            [27049]   \n",
       "12               50880       66643  1436478142968                 []   \n",
       "\n",
       "    item_prop_num_now  \n",
       "2               53040  \n",
       "7               18720  \n",
       "8                8520  \n",
       "10               8400  \n",
       "12              53040  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explod_event.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the purched hist into list \n",
    "event_hist = explod_event.groupby(['timestamp_now','visitorid'])\\\n",
    "                        .agg({'item_prop_text_hist':lambda col: col.tolist(), \n",
    "                              'item_prop_num_hist':lambda col: col.tolist(), \n",
    "                              'itemid_hist': lambda col: col.tolist(),\n",
    "                              'itemid_now': lambda col: col.tolist()[0],\n",
    "                             'item_prop_text_now': lambda col: col.tolist()[0],\n",
    "                             'item_prop_num_now': lambda col: col.tolist()[0]})\\\n",
    "                        .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_now</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>item_prop_text_hist</th>\n",
       "      <th>item_prop_num_hist</th>\n",
       "      <th>itemid_hist</th>\n",
       "      <th>itemid_now</th>\n",
       "      <th>item_prop_text_now</th>\n",
       "      <th>item_prop_num_now</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1431264802442</td>\n",
       "      <td>894034</td>\n",
       "      <td>[[7082]]</td>\n",
       "      <td>[18000]</td>\n",
       "      <td>[262813]</td>\n",
       "      <td>36026</td>\n",
       "      <td>[6895, 18406, 15220, 16079, 26709, 15220, 1607...</td>\n",
       "      <td>9360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1431264802458</td>\n",
       "      <td>894034</td>\n",
       "      <td>[[6895, 18406, 15220, 16079, 26709, 15220, 160...</td>\n",
       "      <td>[9360, 18000]</td>\n",
       "      <td>[36026, 262813]</td>\n",
       "      <td>120050</td>\n",
       "      <td>[2989, 15925, 35315]</td>\n",
       "      <td>23280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1431285199338</td>\n",
       "      <td>176878</td>\n",
       "      <td>[[20300]]</td>\n",
       "      <td>[566280]</td>\n",
       "      <td>[429369]</td>\n",
       "      <td>217089</td>\n",
       "      <td>[34078]</td>\n",
       "      <td>21840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1431286835450</td>\n",
       "      <td>527815</td>\n",
       "      <td>[[47460, 28904]]</td>\n",
       "      <td>[145920]</td>\n",
       "      <td>[40808]</td>\n",
       "      <td>408139</td>\n",
       "      <td>[16136, 15543, 16223, 844, 12759]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1431290048653</td>\n",
       "      <td>1392946</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[121320]</td>\n",
       "      <td>[241555]</td>\n",
       "      <td>412622</td>\n",
       "      <td>[15347, 10705, 21241, 740, 16170, 15347, 15331...</td>\n",
       "      <td>103920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp_now  visitorid  \\\n",
       "0  1431264802442     894034   \n",
       "1  1431264802458     894034   \n",
       "2  1431285199338     176878   \n",
       "3  1431286835450     527815   \n",
       "4  1431290048653    1392946   \n",
       "\n",
       "                                 item_prop_text_hist item_prop_num_hist  \\\n",
       "0                                           [[7082]]            [18000]   \n",
       "1  [[6895, 18406, 15220, 16079, 26709, 15220, 160...      [9360, 18000]   \n",
       "2                                          [[20300]]           [566280]   \n",
       "3                                   [[47460, 28904]]           [145920]   \n",
       "4                                               [[]]           [121320]   \n",
       "\n",
       "       itemid_hist  itemid_now  \\\n",
       "0         [262813]       36026   \n",
       "1  [36026, 262813]      120050   \n",
       "2         [429369]      217089   \n",
       "3          [40808]      408139   \n",
       "4         [241555]      412622   \n",
       "\n",
       "                                  item_prop_text_now  item_prop_num_now  \n",
       "0  [6895, 18406, 15220, 16079, 26709, 15220, 1607...               9360  \n",
       "1                               [2989, 15925, 35315]              23280  \n",
       "2                                            [34078]              21840  \n",
       "3                  [16136, 15543, 16223, 844, 12759]                  0  \n",
       "4  [15347, 10705, 21241, 740, 16170, 15347, 15331...             103920  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_hist.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item in event (item that is purchasing now) is should not appeared in purchasing history \n",
    "# event_hist = event_hist[~ event_hist.apply(lambda x: x.itemid_now in x.itemid_hist, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_hist[\"item_prop_hist_num_count\"] =  event_hist[\"item_prop_num_hist\"].apply(lambda x:len(x))\n",
    "event_hist[\"item_prop_hist_num_mean\"] =  event_hist[\"item_prop_num_hist\"].apply(lambda x: np.mean(x))\n",
    "event_hist[\"item_prop_hist_num_median\"] =  event_hist[\"item_prop_num_hist\"].apply(lambda x:np.median(x))\n",
    "event_hist[\"item_prop_hist_num_max\"] =  event_hist[\"item_prop_num_hist\"].apply(lambda x: np.max(x))\n",
    "event_hist[\"item_prop_hist_num_min\"] =  event_hist[\"item_prop_num_hist\"].apply(lambda x:np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_hist['itemid_hist'] = event_hist['itemid_hist']\\\n",
    "#                             .apply(lambda x: [int(ele) for ele in x[1:-1].split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp_now                  int64\n",
       "visitorid                      int64\n",
       "item_prop_text_hist           object\n",
       "item_prop_num_hist            object\n",
       "itemid_hist                   object\n",
       "itemid_now                     int64\n",
       "item_prop_text_now            object\n",
       "item_prop_num_now              int64\n",
       "item_prop_hist_num_count       int64\n",
       "item_prop_hist_num_mean      float64\n",
       "item_prop_hist_num_median    float64\n",
       "item_prop_hist_num_max         int64\n",
       "item_prop_hist_num_min         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_hist.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trian the model\n",
    "- only use user purchased items info \n",
    "- embedding for purchased item text data \n",
    "    - `itemid_hist`\n",
    "- some statical features for purchased item nuemrical info\n",
    "    - `item_prop_hist_num_count`,`item_prop_hist_num_mean`,`item_prop_hist_num_median`,\n",
    "    `item_prop_hist_num_max`,`item_prop_hist_num_min`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(epoch_num,batch_size):\n",
    "    df = event_hist[[\"itemid_hist\",\"item_prop_hist_num_count\",\n",
    "                                       \"item_prop_hist_num_mean\",\n",
    "                                       \"item_prop_hist_num_median\",\n",
    "                                       \"item_prop_hist_num_max\",\n",
    "                                       \"item_prop_hist_num_min\",'itemid_now']]\n",
    "    dataframe = df.copy()\n",
    "\n",
    "    labels = dataframe.pop('itemid_now')\n",
    "    features = {\n",
    "        'itemid_hist':tf.ragged.constant(dataframe[['itemid_hist']].values, dtype= tf.int32),\n",
    "        'cont_features': tf.constant(dataframe[[\"item_prop_hist_num_count\",\n",
    "                                       \"item_prop_hist_num_mean\",\n",
    "                                       \"item_prop_hist_num_median\",\n",
    "                                       \"item_prop_hist_num_max\",\n",
    "                                       \"item_prop_hist_num_min\"]].values, dtype=tf.float32)\n",
    "    }\n",
    "   \n",
    "    data_set = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "    data_set = data_set.repeat(epoch_num)\n",
    "    data_set = data_set.prefetch(buffer_size=100)\n",
    "    data_set = data_set.batch(batch_size=batch_size)\n",
    "    \n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TF_CONFIG environment variable: {'cluster': {'worker': ['localhost:12345', 'localhost:23456']}, 'task': {'type': 'worker', 'index': 0}}\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:RunConfig initialized for Distribute Coordinator with INDEPENDENT_WORKER mode\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'temp/', '_tf_random_seed': 2019, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x6775c0358>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['localhost:12345', 'localhost:23456']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': 'independent_worker'}\n",
      "INFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.\n",
      "INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['localhost:12345', 'localhost:23456']}, task_type = 'worker', task_id = 0, environment = None, rpc_layer = 'grpc'\n",
      "WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:0',)\n",
      "INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['localhost:12345', 'localhost:23456']}, task_type = 'worker', task_id = 0, num_workers = 2, local_devices = ('/job:worker/task:0',), communication = CollectiveCommunication.AUTO\n",
      "INFO:tensorflow:Starting standard TensorFlow server, target = 'grpc://localhost:12345', session_config= allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "    scoped_allocator_optimization: ON\n",
      "    scoped_allocator_opts {\n",
      "      enable_op: \"CollectiveReduce\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental {\n",
      "  collective_group_leader: \"/job:worker/replica:0/task:0\"\n",
      "}\n",
      "\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:0',)\n",
      "INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['localhost:12345', 'localhost:23456']}, task_type = 'worker', task_id = 0, num_workers = 2, local_devices = ('/job:worker/task:0',), communication = CollectiveCommunication.AUTO\n",
      "INFO:tensorflow:Updated config: {'_model_dir': 'temp/', '_tf_random_seed': 2019, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x6775c0ef0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['localhost:12345', 'localhost:23456']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://localhost:12345', '_evaluation_master': 'grpc://localhost:12345', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 2, '_distribute_coordinator_mode': 'independent_worker'}\n",
      "WARNING:tensorflow:From /Applications/condaSoftware/anaconda3/envs/tf2_3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "INFO:tensorflow:Collective batch_all_reduce: 6 all-reduces, num_workers = 2, communication_hint = AUTO\n",
      "INFO:tensorflow:Collective batch_all_reduce for IndexedSlices: 1 all-reduces, num_workers = 2\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 2, communication_hint = AUTO\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:all_hooks [<tensorflow_estimator.python.estimator.util.DistributedIteratorInitializerHook object at 0x6775d1d68>, <tensorflow.python.training.basic_session_run_hooks.StopAtStepHook object at 0x6775c2ac8>, <tensorflow.python.training.basic_session_run_hooks.NanTensorHook object at 0x6775c71d0>, <tensorflow.python.training.basic_session_run_hooks.LoggingTensorHook object at 0x6775c72b0>, <tensorflow.python.training.basic_session_run_hooks.StepCounterHook object at 0x6775ef320>, <tensorflow.python.training.basic_session_run_hooks.SummarySaverHook object at 0x6776671d0>, <tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x677667128>]\n",
      "INFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:worker/task:0\"\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "    scoped_allocator_optimization: ON\n",
      "    scoped_allocator_opts {\n",
      "      enable_op: \"CollectiveReduce\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental {\n",
      "  collective_group_leader: \"/job:worker/replica:0/task:0\"\n",
      "}\n",
      "\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    }
   ],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    visit_items_index = features['itemid_hist']\n",
    "    cont_features = features['cont_features']\n",
    "\n",
    "    next_visit_item_index = labels\n",
    "\n",
    "    num_buckets = len(text_list)+1  #visit_items_index.values.max()[0]+1\n",
    "    embedding_size = 300\n",
    "    keep_prob = 0.8\n",
    "    top_k = 10\n",
    "\n",
    "    # items embedding \n",
    "    item_embedding = tf.Variable(\n",
    "        tf.random.truncated_normal(\n",
    "            [num_buckets, embedding_size], stddev=1.0 / math.sqrt(embedding_size)\n",
    "        ))\n",
    "\n",
    "    # visited item history\n",
    "    visit_items_embedding = tf.nn.embedding_lookup(item_embedding, visit_items_index)   # [Batch, None, None, embedding]\n",
    "    visit_items_average_embedding = tf.reduce_mean(visit_items_embedding, axis=1)        # [Batch, , None, embedding]\n",
    "    visit_items_average_embedding = tf.reduce_mean(visit_items_average_embedding, axis=1) # [Batch, embedding]\n",
    "\n",
    "    input_embedding = tf.concat([visit_items_average_embedding,cont_features], 1)       #  [Batch, embedding + 5]\n",
    "    # print(\"the shape of input_embedding is:\", input_embedding.shape)\n",
    "\n",
    "    layer_1 = tf.keras.layers.Dense(64, activation=tf.nn.relu, name=\"layer_1\")(input_embedding) \n",
    "\n",
    "    layer_dropout_1 = tf.nn.dropout(layer_1, keep_prob, name=\"layer_dropout_1\")\n",
    "    \n",
    "    layer_2 = tf.keras.layers.Dense(32, \n",
    "                                    activation=tf.nn.relu, \n",
    "                                    name=\"layer_2\")(layer_dropout_1)\n",
    "\n",
    "    layer_dropout_2 = tf.nn.dropout(layer_2, keep_prob, name=\"layer_dropout_2\")\n",
    "\n",
    "   \n",
    "    user_vector = tf.keras.layers.Dense(embedding_size, \n",
    "                                        activation=tf.nn.relu,\n",
    "                                        name=\"user_vector\")(layer_dropout_2)\n",
    "\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        output_embedding = tf.nn.embedding_lookup(item_embedding, next_visit_item_index)   # num * embedding_size\n",
    "        logits = tf.matmul(user_vector, output_embedding, transpose_a=False, transpose_b=True)  # num * num\n",
    "        yhat = tf.nn.softmax(logits)  # num * num\n",
    "        \n",
    "        cross_entropy = tf.reduce_mean(-tf.math.log(tf.linalg.diag_part(yhat) + 1e-16))\n",
    "        \n",
    "        optimizer = tf.compat.v1.train.GradientDescentOptimizer(1e-4)\n",
    "        \n",
    "        train = optimizer.minimize(cross_entropy, tf.compat.v1.train.get_or_create_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=cross_entropy, train_op=train)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        output_embedding = tf.nn.embedding_lookup(item_embedding, next_visit_item_index)  # num * embedding_size\n",
    "        logits = tf.matmul(user_vector, output_embedding, transpose_a=False, transpose_b=True)  # num * num\n",
    "        yhat = tf.nn.softmax(logits)  # num * num\n",
    "        \n",
    "        cross_entropy = tf.reduce_mean(-tf.math.log(tf.linalg.diag_part(yhat) + 1e-16))\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=cross_entropy)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        logits_predict = tf.matmul(user_vector, item_embedding, transpose_a=False, transpose_b=True)  # num *  item_num\n",
    "        yhat_predict = tf.nn.softmax(logits_predict)  # num *  item_num\n",
    "        _, indices = tf.nn.top_k(yhat_predict, k=top_k, sorted=True)\n",
    "        index = tf.identity(indices, name=\"index\")  # num * top_k\n",
    "        predictions = {\n",
    "            \"user_vector\": user_vector,\n",
    "            \"index\": index\n",
    "        }\n",
    "        export_outputs = {\n",
    "            \"prediction\": tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.estimator.RunConfig(\n",
    "    model_dir=\"temp/\",\n",
    "    tf_random_seed=2019,\n",
    "    save_checkpoints_steps=100,\n",
    "    keep_checkpoint_max=5,\n",
    "    log_step_count_steps=100,\n",
    "    train_distribute=strategy\n",
    ")\n",
    "classifier = tf.estimator.Estimator(model_fn=model_fn, config=config)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=lambda: input_fn(\n",
    "        epoch_num=11,\n",
    "        batch_size=32),\n",
    "    max_steps=1000\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=lambda: input_fn(\n",
    "        epoch_num=1,\n",
    "        batch_size=32),\n",
    "    steps=15,           # eval on how many data \n",
    "    start_delay_secs=1, # how many seconds later to start evaluate \n",
    "    throttle_secs=20    # evaluate every 20seconds\n",
    ")\n",
    "\n",
    "tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
